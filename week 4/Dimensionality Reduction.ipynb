{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae0d9551",
   "metadata": {},
   "source": [
    "### **Dimensionality Reduction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa369e75",
   "metadata": {},
   "source": [
    "Datasets are sometimes very large, containing potentially millions of data points across a large numbers of features.\n",
    "\n",
    "Each feature can also be thought of as a ‘dimension’. In some cases, for high-dimensional data, we may want or need to try to reduce the number of dimensions. Reducing the number of dimensions (or reducing the number of features in a dataset) is called ‘dimensionality reduction’"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cc0e21",
   "metadata": {},
   "source": [
    "**Dimensionality reduction** in machine learning (ML) is the process of reducing the number of features or dimensions in a dataset, while preserving the most important information. The objectives of dimensionality reduction are to visualize data easier, understand and analyze, and to improve the performance of ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c272aa3e",
   "metadata": {},
   "source": [
    "The simplest way to do so could simply be to drop some dimensions, and we could even choose to drop the dimensions that seem likely to be the least useful. This would be a simple method of dimensionality reduction. However, this approach is likely to throw away a lot of information, and we wouldn’t necessarily know which features to keep. Typically we want to try to reduce the number of dimensions while still preserving the most information we can from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc0505f",
   "metadata": {},
   "source": [
    "### **When Should You Avoid Using Dimensionality Reduction?**\n",
    "\n",
    "There are several situations where dimensionality reduction techniques are not recommended:\n",
    "\n",
    "- If the dataset is small, the information loss caused by dimensionality reduction techniques may be large, and it may be better to use all the features.\n",
    "\n",
    "- When the data is already well-structured and easy to understand, dimensionality reduction techniques may not be necessary, and it may be better to use all the features as the benefits from interpretability may outweigh gains such as ML performance.\n",
    "\n",
    "- When the data has a non-linear structure, dimensionality reduction techniques such as PCA which only captures linear relationships in the data may not be effective, and other techniques such as t-SNE, UMAP are more appropriate.\n",
    "\n",
    "- When the data is highly skewed, dimensionality reduction techniques such as PCA which assumes a normal distribution of the data may not be effective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39255d0",
   "metadata": {},
   "source": [
    "### **DEMO:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a75ff4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "data = pd.read_csv(\"https://statso.io/wp-content/uploads/2023/06/rfm_data.csv \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96c7d558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>PurchaseDate</th>\n",
       "      <th>TransactionAmount</th>\n",
       "      <th>ProductInformation</th>\n",
       "      <th>OrderID</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8814</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>943.31</td>\n",
       "      <td>Product C</td>\n",
       "      <td>890075</td>\n",
       "      <td>Tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2188</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>463.70</td>\n",
       "      <td>Product A</td>\n",
       "      <td>176819</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID PurchaseDate  TransactionAmount ProductInformation  OrderID  \\\n",
       "0        8814   2023-04-11             943.31          Product C   890075   \n",
       "1        2188   2023-04-11             463.70          Product A   176819   \n",
       "\n",
       "  Location  \n",
       "0    Tokyo  \n",
       "1   London  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832750c4",
   "metadata": {},
   "source": [
    "**First we are going to create a DataFrame to hold the columns you want to preserve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3c10f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_preserve = data[['PurchaseDate', 'Location']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cff851c",
   "metadata": {},
   "source": [
    "We are going to assume that 'CustomerID', 'PurchaseDate', 'OrderID', and 'Location' are not used in dimensionality reduction, so we are ging to drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa5b3600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionAmount</th>\n",
       "      <th>ProductInformation_Product A</th>\n",
       "      <th>ProductInformation_Product B</th>\n",
       "      <th>ProductInformation_Product C</th>\n",
       "      <th>ProductInformation_Product D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>943.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>463.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionAmount  ProductInformation_Product A  \\\n",
       "0             943.31                             0   \n",
       "1             463.70                             1   \n",
       "\n",
       "   ProductInformation_Product B  ProductInformation_Product C  \\\n",
       "0                             0                             1   \n",
       "1                             0                             0   \n",
       "\n",
       "   ProductInformation_Product D  \n",
       "0                             0  \n",
       "1                             0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['CustomerID', 'PurchaseDate', 'OrderID', 'Location']\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "#Then we convery convert categorical data to numerical using one-hot encoding\n",
    "data = pd.get_dummies(data, columns=['ProductInformation'])\n",
    "\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d4499d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data_standardized = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a329171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import StandardScaler\\nfrom sklearn.decomposition import PCA'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply PCA\n",
    "n_components = 2  # Set the number of components you want to reduce to\n",
    "pca = PCA(n_components=n_components)\n",
    "data_pca = pca.fit_transform(data_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "705df5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with reduced dimensions\n",
    "column_names = [f'PC{i+1}' for i in range(n_components)]\n",
    "reduced_data = pd.DataFrame(data=data_pca, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c349d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the reduced data with other relevant columns if needed: Example below concatenates 'PurchaseDate' and 'Location'\n",
    "\n",
    "# Concatenate the reduced data with the columns you want to preserve\n",
    "final_data = pd.concat([columns_to_preserve, reduced_data], axis=1)\n",
    "\n",
    "# Save the reduced data to a new CSV file\n",
    "final_data.to_csv('data/reduced_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b750bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/reduced_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bb6dc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PurchaseDate</th>\n",
       "      <th>Location</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>1.943539</td>\n",
       "      <td>-0.224364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>London</td>\n",
       "      <td>-0.350556</td>\n",
       "      <td>0.232157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>New York</td>\n",
       "      <td>-0.436379</td>\n",
       "      <td>0.269576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>London</td>\n",
       "      <td>-0.404816</td>\n",
       "      <td>0.255815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>Paris</td>\n",
       "      <td>-0.288808</td>\n",
       "      <td>0.205235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PurchaseDate  Location       PC1       PC2\n",
       "0   2023-04-11     Tokyo  1.943539 -0.224364\n",
       "1   2023-04-11    London -0.350556  0.232157\n",
       "2   2023-04-11  New York -0.436379  0.269576\n",
       "3   2023-04-11    London -0.404816  0.255815\n",
       "4   2023-04-11     Paris -0.288808  0.205235"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1399189c",
   "metadata": {},
   "source": [
    "Apart from Principal Component Analysis, **T-distributed stochastic neighbor embedding (t-SNE)**  and **Linear discriminant analysis (LDA)**  are the other two common deminitonalit reduction techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6936d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import T-distributed stochastic neighbor \n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#An example  using T-distributed stochastic neighbor\n",
    "n_components = 2  # Set the number of components you want to reduce to\n",
    "tsne = TSNE(n_components=n_components, random_state=42)  # You can change the random_state for reproducibility\n",
    "data_tsne = tsne.fit_transform(data_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac9c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "Import Linear discriminant analysis (LDA) from SKlearn \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "#An example  using Linear discriminant analysis (LDA)\n",
    "n_components = 2  # Set the number of components you want to reduce to\n",
    "lda = LDA(n_components=n_components)\n",
    "data_lda = lda.fit_transform(data_standardized, data['ProductInformation'])\n",
    "\n",
    "# Create a DataFrame with reduced dimensions\n",
    "column_names = [f'LDA{i+1}' for i in range(n_components)]\n",
    "reduced_data_lda = pd.DataFrame(data=data_lda, columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b1963d",
   "metadata": {},
   "source": [
    "### **Important points:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c92e0d0",
   "metadata": {},
   "source": [
    "- Dimensionality reduction is the process of reducing the number of features in a dataset while retaining as much information as possible.\n",
    "\n",
    "- This can be done to reduce the complexity of a model, improve the performance of a learning algorithm, or make it easier to visualize the data.\n",
    "\n",
    "- Techniques for dimensionality reduction include: principal component analysis (PCA), singular value decomposition (SVD), and linear discriminant analysis (LDA).\n",
    "\n",
    "- Each technique projects the data onto a lower-dimensional space while preserving important information.\n",
    "\n",
    "- Dimensionality reduction is performed during pre-processing stage before building a model to improve the performance\n",
    "\n",
    "- It is important to note that dimensionality reduction can also discard useful information, so care must be taken when applying these techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec10a26",
   "metadata": {},
   "source": [
    "#### **Reference:**\n",
    "https://medium.com/codex/dimensionality-reduction-techniques-for-categorical-continuous-data-75d2bca53100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
